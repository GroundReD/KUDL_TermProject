{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from torch.autograd import Variable\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import torchvision.utils\n",
    "from torchvision.datasets import ImageFolder\n",
    "\n",
    "from data_loader import get_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def discriminator() :\n",
    "    discriminator_model = nn.Sequential(\n",
    "        nn.Conv3d (in_channels=3, out_channels=64, kernel_size=(4, 4, 4), stride=(2, 2, 2), padding=(1, 1, 1)),\n",
    "        nn.LeakyReLU(negative_slope=0.2, inplace=True),\n",
    "\n",
    "        nn.Conv3d(in_channels=64, out_channels=128, kernel_size=(4, 4, 4), stride=(2, 2, 2), padding=(1, 1, 1)),\n",
    "        nn.BatchNorm3d(num_features=128, eps=1e-03),\n",
    "        nn.LeakyReLU(negative_slope=0.2, inplace=True),\n",
    "\n",
    "        nn.Conv3d(in_channels=128, out_channels=256, kernel_size=(4, 4, 4), stride=(2, 2, 2), padding=(1, 1, 1)),\n",
    "        nn.BatchNorm3d(num_features=256, eps=1e-03),\n",
    "        nn.LeakyReLU(negative_slope=0.2, inplace=True),\n",
    "\n",
    "        nn.Conv3d(in_channels=256, out_channels=512, kernel_size=(4, 4, 4), stride=(2, 2, 2), padding=(1, 1, 1)),\n",
    "        nn.BatchNorm3d(num_features=512, eps=1e-03),\n",
    "        nn.LeakyReLU(negative_slope=0.2, inplace=True),\n",
    "\n",
    "        nn.Conv3d(in_channels=512, out_channels=2, kernel_size=(2, 4, 4), stride=(1, 1, 1), padding=(0, 0, 0)),\n",
    "    )\n",
    "\n",
    "    return discriminator_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generator() :\n",
    "    net_video = nn.Sequential(\n",
    "        nn.ConvTranspose3d(in_channels = 100, out_channels = 512, kernel_size=(2,4,4)),\n",
    "        nn.BatchNorm3d(num_features=512),\n",
    "        nn.ReLU(inplace=True),\n",
    "\n",
    "        nn.ConvTranspose3d(in_channels=512, out_channels=256, kernel_size=(4, 4, 4), stride=(2, 2, 2), padding=(1, 1, 1)),\n",
    "        nn.BatchNorm3d(num_features=256),\n",
    "        nn.ReLU(inplace=True),\n",
    "\n",
    "        nn.ConvTranspose3d(in_channels=256, out_channels=128, kernel_size=(4, 4, 4), stride=(2, 2, 2), padding=(1, 1, 1)),\n",
    "        nn.BatchNorm3d(num_features=128),\n",
    "        nn.ReLU(inplace=True),\n",
    "\n",
    "        nn.ConvTranspose3d(in_channels=128, out_channels=64, kernel_size=(4, 4, 4), stride=(2, 2, 2), padding=(1, 1, 1)),\n",
    "        nn.BatchNorm3d(num_features=64),\n",
    "        nn.ReLU(inplace=True),\n",
    "    )\n",
    "\n",
    "    gen_net = nn.Sequential(\n",
    "        net_video,\n",
    "        nn.ConvTranspose3d(in_channels=64, out_channels=3, kernel_size=(4, 4, 4), stride=(2, 2, 2), padding=(1, 1, 1)),\n",
    "        nn.Tanh(),\n",
    "    )\n",
    "\n",
    "    mask_net = nn.Sequential(\n",
    "        net_video,\n",
    "        nn.ConvTranspose3d(in_channels=64, out_channels=1, kernel_size=(4, 4, 4), stride=(2, 2, 2), padding=(1, 1, 1)),\n",
    "        nn.Sigmoid(),\n",
    "    )\n",
    "\n",
    "    static_net = nn.Sequential(\n",
    "        nn.ConvTranspose2d(100, 512, 4, stride=1, padding=0),\n",
    "        nn.BatchNorm2d(num_features=512),\n",
    "        nn.ReLU(inplace=True),\n",
    "\n",
    "        nn.ConvTranspose2d(512, 256, 4, stride=2, padding=1),\n",
    "        nn.BatchNorm2d(num_features=256),\n",
    "        nn.ReLU(inplace=True),\n",
    "\n",
    "        nn.ConvTranspose2d(256, 128, 4, stride=2, padding=1),\n",
    "        nn.BatchNorm2d(num_features=128),\n",
    "        nn.ReLU(inplace=True),\n",
    "\n",
    "        nn.ConvTranspose2d(128, 64, 4, stride=2, padding=1),\n",
    "        nn.BatchNorm2d(num_features=64),\n",
    "        nn.ReLU(inplace=True),\n",
    "\n",
    "        nn.ConvTranspose2d(64, 3, 4, stride=2, padding=1),\n",
    "        nn.Tanh(),\n",
    "    )\n",
    "\n",
    "    return gen_net, mask_net, static_net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_video(gen_net, mask_net, static_net, z) :\n",
    "    z_forward =  z.view(1, 100, 1, 1, 1)\n",
    "    z_backword = z.view(1, 100, 1, 1)\n",
    "\n",
    "    foreground = gen_net(z_forward)\n",
    "\n",
    "    mask = mask_net(z_forward).expand(1, 3, 32, 64, 64)\n",
    "\n",
    "    background = static_net(z_backword).view(1, 3, 1, 64, 64).expand(1, 3, 32, 64, 64)\n",
    "\n",
    "    video = foreground * mask + background * (1 - mask)\n",
    "\n",
    "    return video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def init_weights(m) :\n",
    "    name = type(m)\n",
    "\n",
    "    if name == nn.Conv3d or name == nn.ConvTranspose2d or name == nn.ConvTranspose3d :\n",
    "        m.weight.data.normal_(0.0, 0.01)\n",
    "        m.bias.data.fill_(0)\n",
    "    elif name == nn.BatchNorm2d or name == nn.BatchNorm3d :\n",
    "        m.weight.data.normal_(1.0, 0.02)\n",
    "        m.bias.data.fill_(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "#check GPU\n",
    "is_gpu = torch.cuda.is_available()\n",
    "print(is_gpu)\n",
    "\n",
    "if is_gpu :\n",
    "    dtype = torch.cuda.FloatTensor\n",
    "else :\n",
    "    dtype = torch.FloatTensor\n",
    "\n",
    "D = discriminator()\n",
    "D = D.type(dtype)\n",
    "gen_net, mask_net, static_net = generator()\n",
    "\n",
    "gen_net = gen_net.type(dtype)\n",
    "mask_net = mask_net.type(dtype)\n",
    "static_net = static_net.type(dtype)\n",
    "\n",
    "D.apply(init_weights)\n",
    "gen_net.apply(init_weights)\n",
    "mask_net.apply(init_weights)\n",
    "static_net.apply(init_weights)\n",
    "\n",
    "if is_gpu :\n",
    "    real_labels = Variable(torch.ones(1).type(torch.cuda.LongTensor))\n",
    "    fake_labels = Variable(torch.zeros(1).type(torch.cuda.LongTensor))\n",
    "else :\n",
    "    real_labels = Variable(torch.ones(1).type(torch.LongTensor))\n",
    "    fake_labels = Variable(torch.zeros(1).type(torch.LongTensor))\n",
    "\n",
    "criterion = nn.CrossEntropyLoss().type(dtype)\n",
    "#criterion = nn.BCELoss().type(dtype)\n",
    "#criterion = nn.BCEWithLogitsLoss().type(dtype)\n",
    "\n",
    "d_optimizer = torch.optim.Adam(D.parameters(), lr=2e-3, betas=(0.5, 0.999))\n",
    "g_optimizer = torch.optim.Adam(list(gen_net.parameters()) + list(mask_net.parameters()) + list(static_net.parameters()), lr=2e-3, betas=(0.5, 0.999))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0/1778], d_loss: 1.5011, g_loss: 1.3122\n",
      "Epoch [100/1778], d_loss: 1.6265, g_loss: 1.3133\n",
      "Epoch [200/1778], d_loss: 1.6265, g_loss: 1.3133\n",
      "Epoch [300/1778], d_loss: 1.6264, g_loss: 1.3133\n",
      "Epoch [400/1778], d_loss: 1.6265, g_loss: 1.3133\n",
      "Epoch [500/1778], d_loss: 1.6265, g_loss: 1.3133\n",
      "Epoch [600/1778], d_loss: 1.6255, g_loss: 1.3133\n",
      "Epoch [700/1778], d_loss: 1.6261, g_loss: 1.3133\n",
      "Epoch [800/1778], d_loss: 1.6261, g_loss: 1.3133\n",
      "Epoch [900/1778], d_loss: 1.6254, g_loss: 1.3133\n",
      "Epoch [1000/1778], d_loss: 1.6263, g_loss: 1.3133\n",
      "Epoch [1100/1778], d_loss: 1.6265, g_loss: 1.3133\n",
      "Epoch [1200/1778], d_loss: 1.6265, g_loss: 1.3133\n",
      "Epoch [1300/1778], d_loss: 1.6265, g_loss: 1.3133\n",
      "Epoch [1400/1778], d_loss: 1.6265, g_loss: 1.3133\n",
      "Epoch [1500/1778], d_loss: 1.6265, g_loss: 1.3133\n",
      "Epoch [1600/1778], d_loss: 1.6265, g_loss: 1.3133\n"
     ]
    }
   ],
   "source": [
    "data_loader = get_loader(data_path='./dataset', image_size=64, batch_size=1, num_workers=2)\n",
    "\n",
    "for epoch in range(1, 2) :\n",
    "\n",
    "    for iter, video in enumerate(data_loader) :\n",
    "        # 1. Train Discriminator\n",
    "        video_data = Variable(video).type(dtype)\n",
    "        \n",
    "\n",
    "        # 1-1. Real Video\n",
    "        outputs = D(video_data).view(1, 2)\n",
    "        d_loss_real = criterion(outputs.data, real_labels)\n",
    "\n",
    "        # 1-2. Fake Video\n",
    "        z = Variable(torch.randn(100) * 0.01).type(dtype)\n",
    "        fake_videos = generate_video(gen_net, mask_net, static_net, z)\n",
    "        outputs = D(fake_videos).view(1, 2)\n",
    "        d_loss_fake = criterion(outputs, fake_labels)\n",
    "\n",
    "        d_loss = d_loss_real + d_loss_fake\n",
    "\n",
    "        D.zero_grad()\n",
    "        d_loss.backward()\n",
    "        d_optimizer.step()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        # 2. Train Generator\n",
    "        z = Variable(torch.randn(100) * 0.01).type(dtype)\n",
    "        fake_videos = generate_video(gen_net, mask_net, static_net, z)\n",
    "        outputs = D(fake_videos).view(1, 2)\n",
    "\n",
    "        g_loss = criterion(outputs, real_labels)\n",
    "    \n",
    "        D.zero_grad()\n",
    "        gen_net.zero_grad() \n",
    "        mask_net.zero_grad()\n",
    "        static_net.zero_grad()\n",
    "\n",
    "        g_loss.backward()\n",
    "        g_optimizer.step()\n",
    "        \n",
    "        if iter % 100 == 0 :\n",
    "            print('Epoch [%d/%d], d_loss: %.4f, g_loss: %.4f' % (iter, 1778, d_loss.data[0], g_loss.data[0]))\n",
    "\n",
    "    z = Variable(torch.randn(100) * 0.01).type(dtype)\n",
    "\n",
    "    for i in range(32) :\n",
    "        fake_video = torch.squeeze(generate_video(gen_net, mask_net, static_net, z))[:,i,:,:]\n",
    "        torchvision.utils.save_image(tensor=fake_video.data, filename=\"./test\" + str(i+1) + \".png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
