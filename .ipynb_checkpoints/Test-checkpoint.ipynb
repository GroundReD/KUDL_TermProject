{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from torch.autograd import Variable\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import torchvision.utils\n",
    "from torchvision.datasets import ImageFolder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def discriminator() :\n",
    "    discriminator_model = nn.Sequential(\n",
    "        nn.Conv3d (in_channels=3, out_channels=64, kernel_size=(4, 4, 4), stride=(2, 2, 2), padding=(1, 1, 1)),\n",
    "        nn.LeakyReLU(negative_slope=0.2, inplace=True),\n",
    "\n",
    "        nn.Conv3d(in_channels=64, out_channels=128, kernel_size=(4, 4, 4), stride=(2, 2, 2), padding=(1, 1, 1)),\n",
    "        nn.BatchNorm3d(num_features=128, eps=1e-03),\n",
    "        nn.LeakyReLU(negative_slope=0.2, inplace=True),\n",
    "\n",
    "        nn.Conv3d(in_channels=128, out_channels=256, kernel_size=(4, 4, 4), stride=(2, 2, 2), padding=(1, 1, 1)),\n",
    "        nn.BatchNorm3d(num_features=256, eps=1e-03),\n",
    "        nn.LeakyReLU(negative_slope=0.2, inplace=True),\n",
    "\n",
    "        nn.Conv3d(in_channels=256, out_channels=512, kernel_size=(4, 4, 4), stride=(2, 2, 2), padding=(1, 1, 1)),\n",
    "        nn.BatchNorm3d(num_features=512, eps=1e-03),\n",
    "        nn.LeakyReLU(negative_slope=0.2, inplace=True),\n",
    "\n",
    "        nn.Conv3d(in_channels=512, out_channels=2, kernel_size=(2, 4, 4), stride=(1, 1, 1), padding=(0, 0, 0)),\n",
    "    )\n",
    "\n",
    "    return discriminator_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generator() :\n",
    "    net_video = nn.Sequential(\n",
    "        nn.ConvTranspose3d(in_channels = 100, out_channels = 512, kernel_size=(2,4,4)),\n",
    "        nn.BatchNorm3d(num_features=512),\n",
    "        nn.ReLU(inplace=True),\n",
    "\n",
    "        nn.ConvTranspose3d(in_channels=512, out_channels=256, kernel_size=(4, 4, 4), stride=(2, 2, 2), padding=(1, 1, 1)),\n",
    "        nn.BatchNorm3d(num_features=256),\n",
    "        nn.ReLU(inplace=True),\n",
    "\n",
    "        nn.ConvTranspose3d(in_channels=256, out_channels=128, kernel_size=(4, 4, 4), stride=(2, 2, 2), padding=(1, 1, 1)),\n",
    "        nn.BatchNorm3d(num_features=128),\n",
    "        nn.ReLU(inplace=True),\n",
    "\n",
    "        nn.ConvTranspose3d(in_channels=128, out_channels=64, kernel_size=(4, 4, 4), stride=(2, 2, 2), padding=(1, 1, 1)),\n",
    "        nn.BatchNorm3d(num_features=64),\n",
    "        nn.ReLU(inplace=True),\n",
    "    )\n",
    "\n",
    "    gen_net = nn.Sequential(\n",
    "        net_video,\n",
    "        nn.ConvTranspose3d(in_channels=64, out_channels=3, kernel_size=(4, 4, 4), stride=(2, 2, 2), padding=(1, 1, 1)),\n",
    "        nn.Tanh(),\n",
    "    )\n",
    "\n",
    "    mask_net = nn.Sequential(\n",
    "        net_video,\n",
    "        nn.ConvTranspose3d(in_channels=64, out_channels=1, kernel_size=(4, 4, 4), stride=(2, 2, 2), padding=(1, 1, 1)),\n",
    "        nn.Sigmoid(),\n",
    "    )\n",
    "\n",
    "    static_net = nn.Sequential(\n",
    "        nn.ConvTranspose2d(100, 512, 4, stride=1, padding=0),\n",
    "        nn.BatchNorm2d(num_features=512),\n",
    "        nn.ReLU(inplace=True),\n",
    "\n",
    "        nn.ConvTranspose2d(512, 256, 4, stride=2, padding=1),\n",
    "        nn.BatchNorm2d(num_features=256),\n",
    "        nn.ReLU(inplace=True),\n",
    "\n",
    "        nn.ConvTranspose2d(256, 128, 4, stride=2, padding=1),\n",
    "        nn.BatchNorm2d(num_features=128),\n",
    "        nn.ReLU(inplace=True),\n",
    "\n",
    "        nn.ConvTranspose2d(128, 64, 4, stride=2, padding=1),\n",
    "        nn.BatchNorm2d(num_features=64),\n",
    "        nn.ReLU(inplace=True),\n",
    "\n",
    "        nn.ConvTranspose2d(64, 3, 4, stride=2, padding=1),\n",
    "        nn.Tanh(),\n",
    "    )\n",
    "\n",
    "    return gen_net, mask_net, static_net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_video(gen_net, mask_net, static_net, z) :\n",
    "    z_forward =  z.view(1, 100, 1, 1, 1)\n",
    "    z_backword = z.view(1, 100, 1, 1)\n",
    "\n",
    "    foreground = gen_net(z_forward)\n",
    "\n",
    "    mask = mask_net(z_forward).expand(1, 3, 32, 64, 64)\n",
    "\n",
    "    background = static_net(z_backword).view(1, 3, 1, 64, 64).expand(1, 3, 32, 64, 64)\n",
    "\n",
    "    video = foreground * mask + background * (1 - mask)\n",
    "\n",
    "    return video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def init_weights(m) :\n",
    "    name = type(m)\n",
    "\n",
    "    if name == nn.Conv3d or name == nn.ConvTranspose2d or name == nn.ConvTranspose3d :\n",
    "        m.weight.data.normal_(0.0, 0.01)\n",
    "        m.bias.data.fill_(0)\n",
    "    elif name == nn.BatchNorm2d or name == nn.BatchNorm3d :\n",
    "        m.weight.data.normal_(1.0, 0.02)\n",
    "        m.bias.data.fill_(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Sequential (\n",
       "  (0): ConvTranspose2d(100, 512, kernel_size=(4, 4), stride=(1, 1))\n",
       "  (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)\n",
       "  (2): ReLU (inplace)\n",
       "  (3): ConvTranspose2d(512, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "  (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
       "  (5): ReLU (inplace)\n",
       "  (6): ConvTranspose2d(256, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "  (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
       "  (8): ReLU (inplace)\n",
       "  (9): ConvTranspose2d(128, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "  (10): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True)\n",
       "  (11): ReLU (inplace)\n",
       "  (12): ConvTranspose2d(64, 3, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "  (13): Tanh ()\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check GPU\n",
    "is_gpu = torch.cuda.is_available()\n",
    "print(is_gpu)\n",
    "\n",
    "if is_gpu :\n",
    "    dtype = torch.cuda.FloatTensor\n",
    "else :\n",
    "    dtype = torch.FloatTensor\n",
    "\n",
    "D = discriminator()\n",
    "D = D.type(dtype)\n",
    "gen_net, mask_net, static_net = generator()\n",
    "\n",
    "gen_net = gen_net.type(dtype)\n",
    "mask_net = mask_net.type(dtype)\n",
    "static_net = static_net.type(dtype)\n",
    "\n",
    "D.apply(init_weights)\n",
    "gen_net.apply(init_weights)\n",
    "mask_net.apply(init_weights)\n",
    "static_net.apply(init_weights)\n",
    "\n",
    "if is_gpu :\n",
    "    real_labels = Variable(torch.ones(1).type(torch.cuda.LongTensor))\n",
    "    fake_labels = Variable(torch.zeros(1).type(torch.cuda.LongTensor))\n",
    "else :\n",
    "    real_labels = Variable(torch.ones(1).type(torch.LongTensor))\n",
    "    fake_labels = Variable(torch.zeros(1).type(torch.LongTensor))\n",
    "\n",
    "criterion = nn.CrossEntropyLoss().type(dtype)\n",
    "#criterion = nn.BCELoss().type(dtype)\n",
    "#criterion = nn.BCEWithLogitsLoss().type(dtype)\n",
    "\n",
    "d_optimizer = torch.optim.Adam(D.parameters(), lr=1e-3, betas=(0.5, 0.999))\n",
    "g_optimizer = torch.optim.Adam(list(gen_net.parameters()) + list(mask_net.parameters()) + list(static_net.parameters()), lr=1e-3, betas=(0.5, 0.999))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_transform = torchvision.transforms.Compose([torchvision.transforms.Scale((64,64)), torchvision.transforms.ToTensor()])\n",
    "image_data = ImageFolder(root='./testset/', transform=data_transform)\n",
    "data_loader = DataLoader(image_data, batch_size=1, shuffle=True)\n",
    "\n",
    "video_data = None\n",
    "\n",
    "for data, _ in data_loader:\n",
    "    data.unsqueeze_(2)\n",
    "\n",
    "    if torch.is_tensor(video_data):\n",
    "        video_data = torch.cat((video_data, data), 2)\n",
    "    elif video_data == None:\n",
    "        video_data = data\n",
    "\n",
    "video = Variable(video_data).type(dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [100/1000], d_loss: 29.8783, g_loss: 9.9222, D(x): 0.03, D(G(z)): -0.25\n",
      "Epoch [200/1000], d_loss: 31.6260, g_loss: 9.8444, D(x): 0.03, D(G(z)): 0.08\n",
      "Epoch [300/1000], d_loss: 32.3902, g_loss: 10.7333, D(x): 0.03, D(G(z)): 0.12\n",
      "Epoch [400/1000], d_loss: 33.3533, g_loss: 12.0624, D(x): 0.02, D(G(z)): -0.09\n",
      "Epoch [500/1000], d_loss: 34.0079, g_loss: 17.1418, D(x): 0.02, D(G(z)): 0.03\n",
      "Epoch [600/1000], d_loss: 34.5746, g_loss: 11.5056, D(x): 0.02, D(G(z)): -0.02\n",
      "Epoch [700/1000], d_loss: 35.1832, g_loss: 12.6957, D(x): 0.01, D(G(z)): -0.03\n",
      "Epoch [800/1000], d_loss: 36.0289, g_loss: 12.4593, D(x): 0.01, D(G(z)): 0.06\n",
      "Epoch [900/1000], d_loss: 36.5938, g_loss: 13.7987, D(x): 0.00, D(G(z)): 0.08\n",
      "Epoch [1000/1000], d_loss: 36.9531, g_loss: 13.9372, D(x): 0.00, D(G(z)): 0.05\n",
      "Epoch [1100/1000], d_loss: 37.2159, g_loss: 13.6777, D(x): -0.00, D(G(z)): 0.08\n",
      "Epoch [1200/1000], d_loss: 37.4134, g_loss: 13.7321, D(x): -0.00, D(G(z)): 0.14\n",
      "Epoch [1300/1000], d_loss: 37.5794, g_loss: 13.7511, D(x): -0.01, D(G(z)): 0.17\n",
      "Epoch [1400/1000], d_loss: 37.7155, g_loss: 14.3741, D(x): -0.01, D(G(z)): 0.11\n",
      "Epoch [1500/1000], d_loss: 37.8268, g_loss: 13.1664, D(x): -0.01, D(G(z)): 0.14\n",
      "Epoch [1600/1000], d_loss: 37.9306, g_loss: 17.7494, D(x): -0.01, D(G(z)): 0.05\n",
      "Epoch [1700/1000], d_loss: 38.0182, g_loss: 15.7351, D(x): -0.01, D(G(z)): -0.03\n",
      "Epoch [1800/1000], d_loss: 38.1074, g_loss: 15.0379, D(x): -0.02, D(G(z)): 0.05\n",
      "Epoch [1900/1000], d_loss: 38.1819, g_loss: 13.8394, D(x): -0.02, D(G(z)): 0.06\n",
      "Epoch [2000/1000], d_loss: 38.2655, g_loss: 14.7724, D(x): -0.02, D(G(z)): -0.00\n",
      "Epoch [2100/1000], d_loss: 38.3320, g_loss: 14.5212, D(x): -0.02, D(G(z)): -0.04\n",
      "Epoch [2200/1000], d_loss: 38.3949, g_loss: 14.7660, D(x): -0.02, D(G(z)): -0.05\n",
      "Epoch [2300/1000], d_loss: 38.4440, g_loss: 14.6349, D(x): -0.03, D(G(z)): -0.05\n",
      "Epoch [2400/1000], d_loss: 38.5007, g_loss: 15.3561, D(x): -0.03, D(G(z)): -0.11\n",
      "Epoch [2500/1000], d_loss: 38.5452, g_loss: 15.8579, D(x): -0.03, D(G(z)): -0.12\n",
      "Epoch [2600/1000], d_loss: 38.5850, g_loss: 16.1293, D(x): -0.03, D(G(z)): -0.12\n",
      "Epoch [2700/1000], d_loss: 38.6228, g_loss: 15.1111, D(x): -0.04, D(G(z)): -0.16\n",
      "Epoch [2800/1000], d_loss: 38.6575, g_loss: 15.6863, D(x): -0.04, D(G(z)): -0.21\n",
      "Epoch [2900/1000], d_loss: 38.6873, g_loss: 15.1253, D(x): -0.04, D(G(z)): -0.22\n",
      "Epoch [3000/1000], d_loss: 38.7159, g_loss: 14.6280, D(x): -0.05, D(G(z)): -0.30\n",
      "Epoch [3100/1000], d_loss: 38.7429, g_loss: 14.7487, D(x): -0.05, D(G(z)): -0.35\n",
      "Epoch [3200/1000], d_loss: 38.7679, g_loss: 15.1777, D(x): -0.05, D(G(z)): -0.44\n",
      "Epoch [3300/1000], d_loss: 38.7924, g_loss: 16.9058, D(x): -0.06, D(G(z)): -0.41\n",
      "Epoch [3400/1000], d_loss: 38.8154, g_loss: 17.1863, D(x): -0.06, D(G(z)): -0.53\n",
      "Epoch [3500/1000], d_loss: 38.8388, g_loss: 15.6519, D(x): -0.07, D(G(z)): -0.52\n",
      "Epoch [3600/1000], d_loss: 38.8584, g_loss: 15.7446, D(x): -0.08, D(G(z)): -0.54\n",
      "Epoch [3700/1000], d_loss: 38.8876, g_loss: 15.6529, D(x): -0.08, D(G(z)): -0.58\n",
      "Epoch [3800/1000], d_loss: 38.9138, g_loss: 15.3783, D(x): -0.09, D(G(z)): -0.62\n",
      "Epoch [3900/1000], d_loss: 38.9355, g_loss: 16.4473, D(x): -0.09, D(G(z)): -0.68\n",
      "Epoch [4000/1000], d_loss: 38.9569, g_loss: 16.3760, D(x): -0.10, D(G(z)): -0.73\n",
      "Epoch [4100/1000], d_loss: 38.9740, g_loss: 15.3065, D(x): -0.11, D(G(z)): -0.78\n",
      "Epoch [4200/1000], d_loss: 38.9931, g_loss: 16.2120, D(x): -0.12, D(G(z)): -0.84\n",
      "Epoch [4300/1000], d_loss: 39.0129, g_loss: 15.7267, D(x): -0.12, D(G(z)): -0.83\n",
      "Epoch [4400/1000], d_loss: 39.0316, g_loss: 17.4705, D(x): -0.13, D(G(z)): -0.92\n",
      "Epoch [4500/1000], d_loss: 39.0485, g_loss: 16.4217, D(x): -0.14, D(G(z)): -0.92\n",
      "Epoch [4600/1000], d_loss: 39.0639, g_loss: 22.0110, D(x): -0.14, D(G(z)): -0.87\n",
      "Epoch [4700/1000], d_loss: 39.0815, g_loss: 16.6899, D(x): -0.15, D(G(z)): -1.00\n",
      "Epoch [4800/1000], d_loss: 39.0975, g_loss: 16.8568, D(x): -0.16, D(G(z)): -1.07\n",
      "Epoch [4900/1000], d_loss: 39.1104, g_loss: 16.3449, D(x): -0.16, D(G(z)): -1.10\n",
      "Epoch [5000/1000], d_loss: 39.1265, g_loss: 16.1524, D(x): -0.17, D(G(z)): -1.16\n",
      "Epoch [5100/1000], d_loss: 39.1413, g_loss: 15.9670, D(x): -0.17, D(G(z)): -1.19\n",
      "Epoch [5200/1000], d_loss: 39.1552, g_loss: 17.4063, D(x): -0.18, D(G(z)): -1.17\n",
      "Epoch [5300/1000], d_loss: 39.1688, g_loss: 16.3483, D(x): -0.18, D(G(z)): -1.25\n",
      "Epoch [5400/1000], d_loss: 39.1817, g_loss: 16.4648, D(x): -0.19, D(G(z)): -1.29\n",
      "Epoch [5500/1000], d_loss: 39.1956, g_loss: 17.4245, D(x): -0.19, D(G(z)): -1.33\n",
      "Epoch [5600/1000], d_loss: 39.2090, g_loss: 16.3832, D(x): -0.20, D(G(z)): -1.34\n",
      "Epoch [5700/1000], d_loss: 39.2211, g_loss: 17.1112, D(x): -0.20, D(G(z)): -1.35\n",
      "Epoch [5800/1000], d_loss: 39.2333, g_loss: 18.0036, D(x): -0.21, D(G(z)): -1.36\n",
      "Epoch [5900/1000], d_loss: 39.2462, g_loss: 17.6627, D(x): -0.21, D(G(z)): -1.45\n",
      "Epoch [6000/1000], d_loss: 39.2589, g_loss: 16.4816, D(x): -0.22, D(G(z)): -1.48\n",
      "Epoch [6100/1000], d_loss: 39.2717, g_loss: 17.4045, D(x): -0.22, D(G(z)): -1.48\n",
      "Epoch [6200/1000], d_loss: 39.2838, g_loss: 17.3189, D(x): -0.23, D(G(z)): -1.53\n",
      "Epoch [6300/1000], d_loss: 39.2968, g_loss: 17.0672, D(x): -0.23, D(G(z)): -1.52\n",
      "Epoch [6400/1000], d_loss: 39.3092, g_loss: 18.4751, D(x): -0.24, D(G(z)): -1.50\n",
      "Epoch [6500/1000], d_loss: 39.3212, g_loss: 18.0473, D(x): -0.24, D(G(z)): -1.61\n",
      "Epoch [6600/1000], d_loss: 39.3339, g_loss: 18.1890, D(x): -0.25, D(G(z)): -1.59\n",
      "Epoch [6700/1000], d_loss: 39.3454, g_loss: 17.7067, D(x): -0.25, D(G(z)): -1.58\n",
      "Epoch [6800/1000], d_loss: 39.3593, g_loss: 17.3922, D(x): -0.26, D(G(z)): -1.60\n",
      "Epoch [6900/1000], d_loss: 39.3718, g_loss: 17.3525, D(x): -0.26, D(G(z)): -1.62\n",
      "Epoch [7000/1000], d_loss: 39.3845, g_loss: 18.2081, D(x): -0.27, D(G(z)): -1.61\n",
      "Epoch [7100/1000], d_loss: 39.3983, g_loss: 17.5554, D(x): -0.28, D(G(z)): -1.68\n",
      "Epoch [7200/1000], d_loss: 39.4119, g_loss: 17.9018, D(x): -0.28, D(G(z)): -1.63\n",
      "Epoch [7300/1000], d_loss: 39.4262, g_loss: 20.8737, D(x): -0.29, D(G(z)): -1.54\n",
      "Epoch [7400/1000], d_loss: 39.4414, g_loss: 18.4818, D(x): -0.29, D(G(z)): -1.64\n",
      "Epoch [7500/1000], d_loss: 39.4561, g_loss: 17.7486, D(x): -0.30, D(G(z)): -1.65\n",
      "Epoch [7600/1000], d_loss: 39.4721, g_loss: 17.2347, D(x): -0.31, D(G(z)): -1.69\n",
      "Epoch [7700/1000], d_loss: 39.4887, g_loss: 17.4497, D(x): -0.31, D(G(z)): -1.66\n",
      "Epoch [7800/1000], d_loss: 39.5068, g_loss: 18.5478, D(x): -0.32, D(G(z)): -1.57\n",
      "Epoch [7900/1000], d_loss: 39.5269, g_loss: 18.3905, D(x): -0.33, D(G(z)): -1.54\n",
      "Epoch [8000/1000], d_loss: 39.5481, g_loss: 17.6832, D(x): -0.34, D(G(z)): -1.55\n",
      "Epoch [8100/1000], d_loss: 39.5759, g_loss: 17.4191, D(x): -0.35, D(G(z)): -1.41\n",
      "Epoch [8200/1000], d_loss: 39.6163, g_loss: 16.6905, D(x): -0.37, D(G(z)): -1.45\n",
      "Epoch [8300/1000], d_loss: 39.6696, g_loss: 17.3613, D(x): -0.39, D(G(z)): -1.40\n",
      "Epoch [8400/1000], d_loss: 39.7346, g_loss: 17.2440, D(x): -0.42, D(G(z)): -1.44\n",
      "Epoch [8500/1000], d_loss: 39.8032, g_loss: 17.5280, D(x): -0.45, D(G(z)): -1.48\n",
      "Epoch [8600/1000], d_loss: 39.8726, g_loss: 16.6683, D(x): -0.48, D(G(z)): -1.63\n",
      "Epoch [8700/1000], d_loss: 39.9423, g_loss: 16.3791, D(x): -0.51, D(G(z)): -1.74\n",
      "Epoch [8800/1000], d_loss: 40.0046, g_loss: 17.4886, D(x): -0.53, D(G(z)): -1.80\n",
      "Epoch [8900/1000], d_loss: 40.0619, g_loss: 17.4020, D(x): -0.55, D(G(z)): -1.95\n",
      "Epoch [9000/1000], d_loss: 40.1134, g_loss: 17.5288, D(x): -0.57, D(G(z)): -2.03\n",
      "Epoch [9100/1000], d_loss: 40.1605, g_loss: 17.1145, D(x): -0.59, D(G(z)): -2.13\n",
      "Epoch [9200/1000], d_loss: 40.1998, g_loss: 17.9168, D(x): -0.61, D(G(z)): -2.22\n",
      "Epoch [9300/1000], d_loss: 40.2364, g_loss: 17.7823, D(x): -0.62, D(G(z)): -2.30\n",
      "Epoch [9400/1000], d_loss: 40.2706, g_loss: 17.3572, D(x): -0.63, D(G(z)): -2.35\n",
      "Epoch [9500/1000], d_loss: 40.3023, g_loss: 18.5767, D(x): -0.65, D(G(z)): -2.41\n",
      "Epoch [9600/1000], d_loss: 40.3311, g_loss: 18.2632, D(x): -0.66, D(G(z)): -2.48\n",
      "Epoch [9700/1000], d_loss: 40.3592, g_loss: 18.4936, D(x): -0.67, D(G(z)): -2.50\n",
      "Epoch [9800/1000], d_loss: 40.3840, g_loss: 18.3714, D(x): -0.68, D(G(z)): -2.53\n",
      "Epoch [9900/1000], d_loss: 40.4077, g_loss: 18.8420, D(x): -0.69, D(G(z)): -2.64\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, 1000) :\n",
    "\n",
    "    # 1. Train Discriminator\n",
    "\n",
    "    # 1-1. Real Video\n",
    "    outputs = D(video).view(1, 2)\n",
    "    d_loss_real = criterion(outputs.data, real_labels)\n",
    "\n",
    "    # 1-2. Fake Video\n",
    "    z = Variable(torch.randn(100) * 0.01).type(dtype)\n",
    "    fake_videos = generate_video(gen_net, mask_net, static_net, z)\n",
    "    outputs = D(fake_videos).view(1, 2)\n",
    "    d_loss_fake = criterion(outputs, fake_labels)\n",
    "\n",
    "    d_loss = d_loss_real + d_loss_fake\n",
    "\n",
    "    D.zero_grad()\n",
    "    d_loss.backward()\n",
    "    d_optimizer.step()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # 2. Train Generator\n",
    "    z = Variable(torch.randn(100) * 0.01).type(dtype)\n",
    "    fake_videos = generate_video(gen_net, mask_net, static_net, z)\n",
    "    outputs = D(fake_videos).view(1, 2)\n",
    "\n",
    "    g_loss = criterion(outputs, real_labels)\n",
    "`\n",
    "    D.zero_grad()\n",
    "    gen_net.zero_grad() \n",
    "    mask_net.zero_grad()\n",
    "    static_net.zero_grad()\n",
    "\n",
    "    g_loss.backward()\n",
    "    g_optimizer.step()\n",
    "    \n",
    "    if epoch % 100 == 0 :\n",
    "        print('Epoch [%d/%d], d_loss: %.4f, g_loss: %.4f' % (epoch, 1000, d_loss.data[0], g_loss.data[0]))\n",
    "\n",
    "z = Variable(torch.randn(100) * 0.01).type(dtype)\n",
    "\n",
    "for i in range(32) :\n",
    "    fake_video = torch.squeeze(generate_video(gen_net, mask_net, static_net, z))[:,i,:,:]\n",
    "    torchvision.utils.save_image(tensor=fake_video.data, filename=\"./test\" + str(i+1) + \".png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
